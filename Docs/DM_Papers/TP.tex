%\documentstyle[preprint,aps]{revtex}
\documentstyle[prl,aps]{revtex}

\draft
\tighten
\twocolumn

\begin{document}

\date{\today}

\title{Trace setting purification scheme for the density matrix}

\author{Anders~M.~N.~Niklasson, C.~J.~Tymczak, and Matt Challacombe}

\address{
Theoretical Division, Los Alamos National Laboratory,
Los Alamos, NM 87545, USA}

\maketitle

\begin{abstract}
A scheme for the construction of the density matrix in terms of
a purification expansion of the Hamiltonian operator is proposed. The scheme
works with a predefined occupation number and does not need
the additional adjustment or prior knowledge of the chemical potential.
In this sense the method is related to the trace preserving canonical 
purification scheme by Palser and Manolopoulos \cite{McWeeny60,Palser98}, 
but instead of a fixed trace criteria we only require the correct
occupation at convergence. The two methods are
compared within the MondoSCF suite of linear scaling self-consistent
programs for different materials, and we find an overall improved performance,
especially at low and high occupancies. In comparison
with some variational methods the two schemes has the major advantage of
dealing also with degenerate eigenstates and fractional occupancy. 
Formulas for calculating the fractional filling and degeneracy from 
the density matrix are derived, and alternative critereas to idempotency
in the case of degeneracy and fractional filling are suggested.
Thresholding is analyzed and it is shown how the numerical error 
in the density matrix at convergence is proportional to the upper bound of 
the truncation error in a single iteration and how it is independent of the total 
number of iterations performed in the expansion. 

\keywords{density matrix, purification, linear scaling, electronic structure,
spectral projection, degeneracy}

\end{abstract}


\section{Introduction}

The ability to calculate, form first principles, accurate properties of materials
consisting of million of inequivalent atoms has gained a lot of attention
and there has recently been a large effort to develop numerical methods that computationally 
scale linearly with system size \cite{Goedecker_RMP_99}. There are many different
approaches to this problem. Here we will focus on formulations
based on the single-particle density matrix. 
In the most commonly used formulations, e.g. within density functional theory
and the Kohn-Sham scheme \cite{Hohenberg64,Kohn65}, a set of single-particle
eigenvalue problems have to be solved,
\begin{equation}\label{SE}
H \Psi_i = \varepsilon_i \Psi_i, ~~~ i=1,2,...~,N, ~~~ \varepsilon_1 \leq \varepsilon_2 \leq \ldots ~.
\end{equation}
The solutions can be used to calculate the density
\begin{equation}\label{Density}
n_0 = \sum_{i=1}^{N_e} | \Psi_i |^2
\end{equation}
and the single-particle energy
\begin{equation} \label{Energy}
E = \sum_{i=1}^{N_e} \varepsilon_i.
\end{equation}
$H$ is the Hamiltonian, e.g.\ the single-particle Kohn-Sham Hamiltonian
occurring in density functional calculations,
and $N_e < N$ is the number of occupied states, where $N$ is the total number
of states. For large systems the computational
cost of calculating the eigenvalue problem is high, and normally scales 
with the cube of the system size. Since we often
are interested only in the particle density and the sum of the single-particle energies 
we may try to avoid the task solving the complete eigenvalue problem and
calculating all the individual occupied eigenfunctions. Instead we can formulate 
the energy $E$ in terms of the single-particle density matrix $\rho_0$ such that 
\begin{equation}
\label{E_Trace}
E = Tr[ \rho_0 H ],
\end{equation}
where we assume some matrix representation of the operators,
and the density $n_0$ is given by the diagonal part of the real space representation
of the density matrix, i.e.
\begin{equation}
\label{n_Diag} 
n_0({\bf r}) = \rho_0({\bf r},{\bf r}).
\end{equation}
Thus, instead of solving the eigenvalue problem we can calculate
the density matrix. For large complex systems, with a finite correlation 
length, this approach can usually be performed more efficiently than 
the eigenvalue scheme and instead of a cubic scaling the computational 
cost scales linearly with the system size \cite{Goedecker_RMP_99}.

There are essentially two different approaches to constructing 
the single-particle density matrix. The first method is via 
the functional minimization with $\rho_0$ given by
\begin{equation}
\label{FMin}
Tr[ \rho_0 H ]  = \min_{\rho} ~ Tr[ \rho H ]
\end{equation}
with $\rho$ constrained by commutation, $[H,\rho_0] =0$, idempotency,
$\rho = \rho^2$, and conservation of particles, $Tr [\rho ] = N_e$,
Refs.\ \cite{Sameh82,Li93,Carlsson95,Hernandez96,Kohn96,Daniels97,Yang97,Stephan98,Challacombe99,Haynes99,Bowler99,Daniels99}.
The second approach is via the construction
\begin{equation}
\label{Heavyside}
\rho_0 = \theta ( \mu I - H ),
\end{equation}
where $\theta$ is the step function setting all eigenvalues
above the chemical potential $\mu$ to $0$ and all the occupied eigenvalues
below $\mu$ to $1$, 
Refs.\ \cite{Bowler99,Daniels99,McWeeny60,Goedecker94,Palser98,Beylkin99,Holas01,Niklasson02,Kenney95}.
In the case of finite temperatures $\theta$ may be replaced by the Fermi-Dirac distribution.

The techniques for calculating the density matrix
from the two formulations Eqs.\ (\ref{FMin}) and (\ref{Heavyside})
can generally be seen as polynomial expansions of the density matrix $\rho_0$ in terms of 
the Hamiltonian operator, i.e. $\rho_0 = {\cal P}(H)$ for some polynomial ${\cal P}$.
In an iterative approach this expansion can be formulated as
\begin{enumerate}
\item $X_0 = P_{(0)}( H)$
\item $X_{n+1} = P_{(n+1)}( H, X_n)$, ~~~ n = 0,1,2, \ldots
\item $\rho_0 = \lim_{n \rightarrow \infty} X_n,$
\end{enumerate}
i.e. 
\begin{equation} \label{PolD}
\rho_0 = {\cal P}( H) = 
\ldots P_{(n)}(\ldots P_{(2)}(H,P_{(1)}(H)) \ldots )\ldots~.
\end{equation}
The polynomials $P_{(n+1)}( H, X_n)$ are chosen
to achieve a rapid convergence under the conditions of idempotency
and particle conservation. They may either be chosen from
a constrained conjugate gradient minimization of $Tr [\rho H ]$
or as a fast expansion of a step function $\theta(\mu I - H)$. 
Each computational step consists of 
matrix additions and multiplications. The problem is to
find a rapidly convergent expansion that minimizes the number of
matrix-matrix multiplications since these operations arithmetically
are the most time consuming. To improve the matrix sparsity different
schemes apply thresholding of elements after each matrix multiplications, 
either for elements that are below a small threshold or 
outside some radius of interaction.
In purification schemes this introduces error leading to a small violation 
in the commutation between $X_n$ and $H$. To minimize this error the number 
of matrix multiplications should be kept low.
In many practical implementations the approximate
density matrices $X_n$ are all sparse. Since the density matrix is idempotent,
powers of $X_n$ close to convergence will preserve their sparsity structure.
Matrix multiplications can therefore often be performed very efficiently, usually
with a computational cost scaling linearly or close to linearly with the number of
non-zero entries of the density matrix. The property of matrix sparsity is essential
for the success of density matrix schemes and with a correctly chosen basis it can be fulfilled.
For example, for materials with a band gap real space
representations of the density matrix are sparse \cite{Kohn59,Baer97,Stephan00}
due to a finite correlation lengths, usually referred to as nearsightedness \cite{Kohn96},
and within other representations, such as a biorthogonal multi-resolution
wavelet basis, or a density matrix renormalization group approach, the density 
matrix is sparse also for metallic materials \cite{Niklasson02,Beylkin91,Goedecker99,White92}. 
We can therefore always assume that the property of matrix sparsity 
will hold within some appropriate representation. 

In the present article we propose a purification, or spectral projection,
scheme for the expansion of the density matrix. There are several different
projection schemes and we distinguish between: {\it 1)} {\it grand canonical}
schemes, with a step function  expansion around a predefined chemical potential \cite{McWeeny60},
{\it 2)} {\it canonical trace conserving} schemes, with a fixed trace
in each iteration step \cite{Palser98}, {\it 3)} {\it trace correcting} methods,
where the trace only reaches the correct value at convergence \cite{Niklasson02b}, 
and finally (presented in this article) {\it 4)} {\it trace setting} algorithms, where the trace is set 
to the correct value in most steps and towards convergence. The so-called matrix sign function
expansions are equivalent with the purification schemes via a trivial
linear transform and the corresponding methods are in parallel with the purification schemes.

The efficiency of the different density-matrix schemes strongly
varies depending on the particular characteristics of the problem such as
the existence of a band gap, a predefined chemical potential, degeneracy, filling factor, 
fractional occupancy, self-consistency cycles, memory requirements, thresholding, 
basis set and system size. 
In the present work we have formulated an efficient trace setting expansion 
algorithm for computing the density matrix along the lines described above which
is simple and general. The method works with a predefined occupation, i.e.
there is no need to have prior knowledge of, or to adjust the chemical potential. 
A scheme with this feature was recently constructed by Palser and Manolopoulos 
(PM) \cite{Palser98}. By using a starting guess $X_0$ with the trace equal to 
the occupation number and thereafter performing trace-conserving
spectral projections, $X_n$ converges to the correct density matrix without
prior knowledge of the chemical potential. The PM scheme has an excellent
performance compared to other methods \cite{Daniels99,Palser98}, it also
has the great advantage of being able to deal with degenerate systems,
including fractional occupancy.
However, due to the constraint of trace conservation the method is inefficient
at low and high partial occupancy. This is of great concern,
for example, when using a multi-resolution wavelet representation for metallic problems,
since the fractional filling in this case is low. The same
problem occurs with a minimal basis set at both high and low
occupancies. Here we present a simple and general trace setting algorithm that avoids 
this particular problem, that also deals with degeneracy and fractional occupancy,
and that converges more rapidly.

First we discuss the general approach for the trace setting method,
thereafter we demonstrate an efficient practical algorithm. 
The problem with degenerate eigenstates and fractional occupancy is discussed and formulas 
for calculating the fractional filling and degeneracy from the density matrix 
are derived. Thresholding is discussed and how it affects
the numerical accuracy and stability.
To demonstrate efficiency, the scheme, implemented in the MondoSCF suite of linear 
scaling self-consistent algorithms \cite{Mondo}, is compared to the PM scheme 
for a set of different materials. 


\section{Trace setting purification}

The general idea behind purification, or spectral projection, for the calculation
of the density matrix is based on an iterative expansion of the
Hamiltonian in terms of a continuously increasing spectral projection 
polynomial $P(x)$, $x \in [0,1]$,
with stationary fixed end points extremums at $0$ and $1$, 
i.e. $P(0) = 0$ and $P(1) = 1$. 
It can be shown that a combined iterative series of such polynomials, 
$\ldots P(P(x)) \ldots$,  
converges to a step function with a step somewhere in $[0,1]$. 
For example, the grand canonical McWeeny purification scheme \cite{McWeeny60,Palser98}
applies an iterative procedure based on the polynomial expansion
\begin{equation} \label{P3}
X_{n+1} = P_{\rm McW}(X_n) = 3 X_n^2 - 2 X_n^3, ~~~~~ n = 0,1,2, \ldots
\end{equation}
where
\begin{equation} \label{Pur2}
X_0 = \alpha(\mu { I} - { H}) + \beta{ I}
\end{equation}
with
\begin{equation} \label{StartG}
\alpha = {\rm min} \left\{ \beta[\varepsilon_{\rm max} - \mu]^{-1},
(1-\beta)[\mu - \varepsilon_{\rm min}]^{-1} \right\}.
\end{equation}
The constant $\beta$ is the inflection point where $P(x) = x$ and for 
the symmetric McWeeny polynomials $\beta = 1/2$. With this fixed
inflection point the step is formed at $x=0.5$. This scheme is very
efficient if the chemical potential $\mu$ is known in advance. If this
is not the case $\mu$ has to be adjusted until the correct trace, i.e. occupancy, 
is reached. However, a projection polynomial $P(x)$ can be modified
such that the trace is set to the expected value. This can be achieved
applying a composite projection with a purification polynomial $F(x)$ 
combined with a second additional perturbation polynomial $\gamma G(x)$ 
weighted by a factor $\gamma$ chosen such that the combined purification sets 
the trace to the correct value $N_e$, i.e.
\begin{equation} \label{NT}
X_{n+1} = P(X_n) = F(X_n) + \gamma_n G(X_n)
\end{equation}
with \begin{equation} \label{gamma}
\gamma_n = (N_e - Tr[F(X_n)])/Tr[G(X_n)].
\end{equation}
An example of a $F(x)$ and $G(x)$ and their sum for some
different values of $\gamma_n$ is shown in Fig. \ref{Fig_F_G}.
Notice, that if the value of $\gamma_n$ is too large we may create
a composite polynomial $P(x)$ that no longer is a continuously  increasing
function in $[0,1]$, but has an extremum with values below or above $[0,1]$.
This, means that the expansion series does not necessary converge
to the desired step function, and that eigenvalues might be thrown out
of the interval $[0,1]$ leading to divergence and instability.
We can therefore not always set the trace as we wish and
the adjusting parameter $\gamma$ must be bounded in order to preserve
stability. The problem arises when too many eigenvalues are
either too low or too high such that the flexible inflection
point, acting like a chemical potential, is out of bounds.
One way of fixing this problem is to apply an eigenvalue
redistribution. This can be done by using the spectral
projection functions  $P(x) = x^2$
or $P(x) = 2x-x^2$, as shown in Fig.\ \ref{Fig_F_G}, whenever $\gamma_n$ is 
too large or to small. In a redistribution step the trace will change 
such that
\begin{equation}
\left \{ \begin{array}{ll}
Tr[X_n^2] & < Tr[X_n]\\
Tr[2X_n-X_n^2] & > Tr[X_n].
\end{array} \right.
\end{equation}
With sufficiently
redistributed eigenvalues the trace setting purification
step can be applied with $\gamma_n$ within
the bounds of stability. All projection
polynomials are continuously increasing with fixed end
points at $0$ and $1$ and the expansion converge
to a step function with a step automatically adjusted to
the corresponding unknown chemical potential. This means
that the converged density matrix is idempotent and with
the correct number of occupied states. For the particular
example demonstrated below one can also show that the
value of $\gamma_n$ close to convergence has a value within
the bounds of stability, i.e. such that the trace setting
purification steps always can be applied at the final projection steps.

Our particular choice of $F$ and $G$ for the trace setting projection are
\begin{equation} \label{FG}
\left\{ \begin{array}{ll}
F(x) &= x^2 (4x-3x^2) \\
G(x) &= x^2 (1-x)^2 ,
\end{array} \right.
\end{equation}
which are the depicted functions in Fig. \ref{Fig_F_G}.
The adjustment factor $\gamma$ is bounded such that $\gamma \in [0,6]$.
At convergence $\gamma \rightarrow 3$,
which means that the expansion polynomial $P(x) = F(x) + \gamma G(x)$ 
finally converges to the McWeeny polynomial similar to the PM scheme.
The choice of $F$ and $G$ is quite arbitrary, but this particular
choice has turned out to be both efficient and simple.
The fourth order projection polynomial $F(x)$ 
requires only two matrix multiplications, the same as for
the third order McWeeny polynomial, but with one additional
vanishing derivative at $x=0$. Adding the perturbation $\gamma G(x)$ with
$\gamma$ increasing from $0$ to $6$ continuously changes the composite 
polynomial $F(x) + \gamma G(x)$ to $F$'s mirror function at $\gamma = 6$ 
with the extra vanishing derivative at $x=1$.
Many other choices of $F$ and $G$ can be made, maybe even more efficient than
what's given in Eq.\ (\ref{FG}). In this way the trace setting
expansion technique can be viewed as a framework for a set
of purification polynomials of varying order.
The algorithm can be described by the following pseudo-code:
\begin{equation} \label{Alg}
\begin{array}{l}
{\it function~ } \rho_0( H, N_e, {\it ErrorLimit})\\
{\it estimate~} \varepsilon_0(H),~\varepsilon_N(H) \\
X_0 = (\varepsilon_{\rm N}I-H)/(\varepsilon_{\rm N}-\varepsilon_{\rm 0}) \\
{\it while~ Error > ErrorLimit} \\
~~ \gamma_n =(N_e - Tr [F(X_n ) ])/Tr [G(X_n ) ]\\
~~ {\it if}~ \gamma_n  > \gamma_{\rm max}  \\
~~ ~~ X_{n+1} = 2X_n-X_n^2  \\
~~ {\it else~ if}~ \gamma_n  < \gamma_{\rm min}  \\
~~ ~~ X_{n+1} = X_n^2 \\
~~ {\it else}\\
~~ ~~ X_{n+1} = F(X_n) + \gamma_n  G(X_n) \\
~~ {\it end}\\
~~ {\it estimate~ Error} \\
{\it endwhile}\\
\rho_0 = X_n .
\end{array}
\end{equation}
The estimate of the the spectral bounds of $H$, i.e. 
$\varepsilon_0(H)$ and $\varepsilon_N(H)$ can be given
by, for example, Gersgorin estimates \cite{Palser98}
or via a couple of Lanczos iterations \cite{Daniels99},
with only a small extra computational cost. 


\section{Degeneracy}

One advantage with the trace setting scheme and the trace
conserving PM scheme, compared to some variational schemes \cite{Li93},
are their ability to deal with degeneracy and fractional occupancy.
Below we briefly discuss the problem with degeneracy and fractional
occupancy, how they destroys idempotency and how they can be calculated
from the density matrix.

Consider the density matrix $\rho_0$  with a $\nu$ folded degeneracy
with $n_d$ occupied degenerate states. The trace of the density matrix
can be described as
\begin{equation}
Tr [ \rho_0  ] = N_e = N_e-n_d + \nu \tau,
\end{equation}
where $\tau = n_d/\nu$ is the filling factor of the degenerate states.
In the case of fractional filling of a non-degenerate state at the
chemical potential $\nu = 1$ and $\tau = n_d < 1$.
The density matrix can be described within the bra-ket notation as
\begin{equation}
\rho_0 = \sum_{ i=1 }^{ N_e - n_d } |\Psi_i >< \Psi_i | + 
\sum_{ i= N_e - n_d + 1 }^{ N_e - n_d + \nu } \tau | \Psi_i> < \Psi_i |
\end{equation}
and with an orthogonal representation we have that
\begin{equation}
\rho_0^m = \sum_{i=1}^{N_e-n_d} |\Psi_i><\Psi_i| + 
\sum_{i=N_e-n_d + 1}^{N_e - n_d +\nu} \tau^m |\Psi_i><\Psi_i|.
\end{equation}
For powers of the density matrix $(m \geq 1)$ we thus have that
\begin{equation} \label{Rhom}
Tr [ \rho_0^m  ] = N_e - n_d + \nu \tau^m \neq Tr  [ \rho_0  ] = N_e.
\end{equation}
From Eq.\ (\ref{Rhom}) we see that idempotency is not
fulfilled in the case of degeneracy or fractional filling. 
This means, for example, that grand canonical purification does not work and
that the McWeeny constraint in conjugate gradient
minimization schemes cannot be applied \cite{Li93}.
In order to achieve a constrained search also
in the degenerate case the trace imposing polynomials
$F(S) + \gamma G(S)$ above, or the trace conserving polynomials
in the canonical PM scheme may possibly be used as alternatives.

Equation (\ref{Rhom}) can be used, as long as
$n \neq \nu$, to calculate the degenerate filling factor and the degeneracy.
Solving the equations (with $m=1,2,3$) for the degeneracy and occupancy
of the degenerate states we get
\begin{equation}
n_d = \frac{(Tr [\rho_0-\rho_0^2 ])^2}{Tr [\rho_0-2\rho_0^2+\rho_0^3 ]},
\end{equation}
\begin{equation}
\nu = \frac{(Tr [\rho_0-\rho_0^2 ])^3}{Tr [\rho_0^2-\rho_0^3 ]Tr [\rho_0-2\rho_0^2+\rho_0^3 ]}
\end{equation}
and
\begin{equation}
\tau = \frac{Tr [\rho_0^2-\rho_0^3 ]}{Tr [\rho_0-\rho_0^2 ]}.
\end{equation}
These formulas can be viewed as alternative conditions to idempotency
for a degenerate density matrix or in the case of fractional occupancy. 
The relations can also be used
to derive the value of $\gamma_n$ at convergence. For the particular
choice of functions $F$ and $G$ above, Eq.\ (\ref{FG}), we have that
\begin{equation}
\lim_{n \rightarrow \infty} \gamma_n = \frac{n_d - \nu F(\tau )}
                                               {\nu G(\tau )}.
\end{equation}
Notice, that if $\gamma_{\infty}$
is outside its bounds of stability, i.e.\ if $\gamma_{\infty} \notin [0,6]$, we cannot deal with
degeneracy and fractional filling. The scheme will still
converge, but not to the correct density matrix. For example,
a 100 folded degeneracy requires $n_d \in [24,76]$ otherwise
$\gamma$ will be out of bound at convergence. This puts some
limitations on the ability to treat degeneracy and fractional filling
with the proposed trace setting algorithm.


\section{Thresholding and Stability}

To increase sparsity of the constituent matrices in the expansion series
we may apply thresholding, i.e. all elements below a certain threshold
are removed. This introduces small errors that propagate through the
iterations. In the present case of purification the error does not
effect the final occupancy or the idempotency (or corresponding criteria
in the degenerate case). However, the commutation between the density
matrix and the Hamiltonian, $[H,\rho_0]$, is affected and may deviate from $0$. 
This means that the set of eigenstates spanning the Hamiltonian is different 
from the set spanning the density matrix and the solution may therefore be wrong.
The error is initially growing with an exponential factor, but at convergence
the error growth disappears due to idempotency.
As will be shown below, the apparently dangerous exponential 
growth factor does not lead to any serious problems and the idempotency
guarantees that convergence is preserved, i.e. that the final 
idempotent solution is stable and does not drastically change 
with iterations and has a well controlled total error.

The major error due to thresholding occurs because of the matrix-matrix
multiplications. The multiplications are also responsible for the
necessity of thresholding since they may reduce matrix sparsety.
Additions and scalar multiplications have a much smaller effect.
To understand the error growth we therefore have to study how
the accumulated error growths with matrix-matrix multiplications.
Assume $X$ is the exact solution and ${\widetilde X} = X + \varepsilon$ is
the approximate solution, with an error matrix $\varepsilon$ due to the
thresholding. In a single multiplication the  new approximation is
\begin{equation}
{\widetilde X}^2 = X^2 + \{ \varepsilon,X \} + {\cal O}(\varepsilon^2),
\end{equation}
where $\{ \varepsilon,X \}$ is the anti-commutator. If second and higher
order error terms in $\varepsilon$ are neglected we have after repeated
matrix multiplications that
\begin{equation}
{\widetilde X}^{2^M} = X^{2^M} + \{ \ldots \{\{ \varepsilon,X \},X^2 \} \ldots,X^{2^M}\}.
\end{equation}
If $\| X \| < 1$ the accumulated error due to a single thresholding is
\begin{equation}
\| \{ \ldots \{\{ \varepsilon,X \},X^2 \} \ldots,X^{2^M}\} \| < 2^M \|\varepsilon\|.
\end{equation}
The sum over all accumulated errors after $M$ number of multiplications, where
the individual threshold errors are assumed to be bounded by $\|\varepsilon\|$, is thus
\begin{equation}
\label{Acc}
\sum_{i=1}^{M} 2^i \|\varepsilon\| = 2(2^M-1)\|\varepsilon\|.
\end{equation}
This looks as a terrible behaviour with an exponential growth factor. However,
the number of matrix multiplications necessary to achieve idempotency convergence $M$
in purification schemes was recently shown to scale as \cite{Niklasson02b}
\begin{equation}
\label{Mlog}
M = \alpha + \beta \log_2 \Delta g^{-1},
\end{equation}
where $\Delta g$ is the band gap at the chemical potential, and
the constants $\alpha$ and $\beta$ are determined by the particular
projection polynomial, occupancy and required error limit.
The relation is derived with exact arithmetics, but is here assumed to
be true also in the case of finite numerics.
If Eq.\ (\ref{Mlog}) is included into Eq.\ (\ref{Acc}), the expression for the total
accumulated error in $X$ after $M$ multiplcations (corresponding
to $n$ purification steps) can be estimated by
\begin{equation}
\| {\widetilde X}_n - X_n \| < 
\left( \frac{2^{\alpha+1}}{\Delta g ^{\beta}} - 2 \right) \|\varepsilon\|.
\end{equation}
This equation, though only derived for the errors due to matrix multiplication, 
illustrates how the error bound is proportional to the truncation error and
independent of the number of matrix multiplications. The main
point is to illustrate how the exponential error growth factor dissapears
thanks to the weak linear realationship between the number
of matrix multiplications and the logarithm of the inverse band gap.
The expression can also be used to estimate an $ErrorLimit$ in Eq.\ (\ref{Alg})
beyond which further iteration not give any improvement.
However, notice that for very large metallic systems, where the
bandgap dissapears as $1/N$ of the system size $N$, we 
may get problems since the error in this case grows with 
a prefactor in polynomial order as $\sim N^{\beta}$.
This may set an upper bound for the system size possible to
treat with the presented method and close to convergency we may
need to use an alternative approach. 

{\it Should maybe be skipped? As a rough estimate we
find that one million basis functions (or possibly one million 
atoms in an atomic block partioned representation with threshold on blocks??)
would require a threshold of $< 10^{-10}$ to get any 
reasonable results in the case of a metal, which probably 
is close to a practical limit. Another serious problem is
the decreased matrix sparsity due to the reduced threshold.
For a metallic system we may therefore not expect a perfect
linear scaling. However, with an appropiate basis choice,
and/or thresholds that commute with the Hamiltonian,
(this might be of importance and should be thought over a lot!
The jacobi rotation idea is just one possibility!!
Thresholding on "commuting" graphs could be another!!),
these problems might be solved.}

To analyze convergence properties and stability around idempotency
we look at the error behavior for the WcWeeny purification,
which is the approximate projection applied close idempotency
in the non-degenerate case. Let ${ \widetilde X }_n = P + e_n$,
where $P$ is the closest idempotent solution to the density matrix
approximation ${ \widetilde X }_n$. The deviation is given by
the idempotency error $e_n$. Applying one McWeeny step 
combined with a threshold $\varepsilon_n$ we get
\begin{equation}
\begin{array}{ll}
{ \widetilde X }_{n+1} &= 3{ \widetilde X }_{n}^2-2{ \widetilde X }_{n}^3\\
&=P+e_{n+1} \\ & = P + \left[ [e_n,P],P\right] + {\cal O}({e_n}^2) + \varepsilon_n,
\end{array}
\end{equation}
i.e.\ the idempotency error behaves as
\begin{equation}
e_{n+1} =  \left[ [e_n,P],P\right] + {\cal O}({e_n}^2) + \varepsilon_n.
\end{equation}
In the case of exact arithmetic when $[{ \widetilde X }_n,P]= \varepsilon_n=0$
we thus find the well known quadratic convergence. Close to idempotency
the second order term ${\cal O}({e_n}^2)$ is neglibly small and the
only source of deviation is the truncation error. 
In this case one can show that
\begin{equation}
e_{n+2} =  \left[ [e_n,P],P\right] + \left[ [\varepsilon_n,P],P\right] + \varepsilon_{n+1}.
\end{equation}
If $[\varepsilon_i,P] = 0,~ (i \ge n)$ this equation 
has the fixed solution $e_{i+1} = e_{n+1} + \varepsilon_{i},~ (i > n)$, which means that the
density approximation does not drift with further iterations.
The criterea for stability around an idempotent solution is thus
determined by the commutation between the truncation error $\varepsilon_n$ and
the idempotent solution $P$. Assuming that ${ \widetilde X }_{n}$ is almost
idempotent, i.e. ${ \widetilde X }_{n}^2 \approx { \widetilde X }_{n}$,
the truncation error will be small and the numerical drift around
convergence will be neglible. This is also true for the single particle 
energy that around the idempotency convergnce $P$ is given by
\begin{equation}
E_n = Tr(PH) + 2Tr(PH[P,e_n]).
\end{equation}

What also must be considered {Great CJ!!!} is the drift in $e_n$ compared
to the total accumulated error. This error manifest itself in the
deviation between $P$ and the true exact value of the density matrix $\rho_0$.
Since this error unusally is orders of magnitude larger than $e_n$
a drift due to $[\varepsilon_i,P] \ne 0$ is diminishingly small.

Below we will by numerical examples for some realistic systems illustrate
the behavior of the accumulated error and the numerical stability at idempotency.


\section{Results}

In order to demonstrate the ability with the new trace setting scheme 
compared to the PM scheme we show some results of the number of matrix
multiplications necessary to achieve convergence for some different 
materials with the two methods. The implementation was made in
the MondoSCF suite of linear scaling self-consistent algorithms
\cite{Mondo}. ... ! CJ

We also compare the CPU time as a function of system size for
the two methods. Figure ... ! CJ

In the case of thresholding, performed in order to increase
matrix sparsity and computational speed, we have applied ...
Figure/Table ... shows how .... ! CJ

A main reason for the increased efficiency is the fact that
the derivative at $0$ and $1$ of the spectral projections used
in the PM scheme approaches $1$ in the limit of no or maximum
occupancy. This leads to a very slow convergence and is avoided
in the trace setting scheme. Moreover, it is more efficient to 
work with a 4th order polynomials. In this way one extra vanishing
derivative at the fixed points may be achieved, but without any
extra computational cost since a 4th order polynomial can be
calculated with only to matrix-matrix multiplications. The
same number of matrix multiplications is needed for a 3rd
order polynomial. Order 2, 4 and 9 seems to be optimal \cite{Niklasson02}.


\section{Summary}

In summary we have proposed a general, simple, and efficient 
trace setting density-matrix expansion algorithm that converges 
to the correct occupation without prior knowledge of the chemical
potential. The scheme was shown to compare favorably with the
similar canonical trace conserving PM method, especially at
low and high occupancies. The methods ability to give the
correct expansion also for degenerate systems or for problems
with a fractional occupancy was discussed
and formulas for calculating the degeneracy and filling factors
from the density matrix were derived. The relations can
be used as alternative conditions to idempotency in the
case of degeneracy and fractional occupation.
The numerical stability in the case of thresholding
was discussed and it was shown that the upper bound of 
total accumulated error of the converged density matrix is independent
of the number of matrix multiplications. The main error 
is instead due to the size of the inverse band gap which, however,
may lead to problems for large metallic systems.


\section{Acknowledgement}

\begin{references}

\bibitem{Goedecker_RMP_99} S. Goedecker,
Rev.\ Mod.\ Phys. {\bf 71}, 1085 (1999).

\bibitem{Hohenberg64} P. Hohenberg and W. Kohn,
Phys.\ Rev.\ {\bf 136}, B864 (1964).

\bibitem{Kohn65} W. Kohn and L.J. Sham,
Phys.\ Rev.\ {\bf A1133} (1965).

\bibitem{Sameh82}  A.\ H. Sameh and J.\ A. Wisniewski,
SIAM Journal on Numerical Analysis {\bf 19}, 1243 (1982).

\bibitem{Li93} X.\ -P. Li, W. Nunes, and D. Vanderbilt,
Phys.\ Rev.\ B {\bf 47}, 10891 (1993).

\bibitem{Carlsson95} A. E. Carlsson,
Phys.\ Rev.\ B {\bf 51}, 13 935 (1995).

\bibitem{Hernandez96} E. Hernandez, M.\ J. Gillan, and C.\ M. Goringe,
Phys.\ Rev.\ B {\bf 53}, 7147 (1996).

\bibitem{Kohn96} W. Kohn,
Phys.\ Rev.\ Lett. {\bf 76}, 3168 (1996).

\bibitem{Daniels97} A.\ D. Daniels, J.\ M. Millam, and G.\ E.\ Scuseria,
J.\ Chem.\ Phys. {\bf 107}, 425 (1997).

\bibitem{Yang97} W. Yang,
Phys.\ Rev.\ B {\bf 56}, 9294 (1997).

\bibitem{Stephan98} U. Stephan, and D.\ A. Drabold,
Phys.\ Rev.\ B {\bf 57}, 6391 (1998).

\bibitem{Challacombe99} M. Challacombe,
J.\ Chem.\ Phys. {\bf 110}, 2332 (1999).

\bibitem{Haynes99} P.\ D. Haynes, and M.\ C. Payne,
Phys.\ Rev.\ B {\bf 59}, 12 173 (1999).

\bibitem{Bowler99} D.\ R. Bowler and M.\ J. Gillan,
Comp.\ Phys.\ Comm. {\bf 120}, 95 (1999).

\bibitem{Daniels99} A.\ D. Daniels and G.\ E.\ Scuseria,
J.\ Chem.\ Phys. {\bf 110}, 1321 (1999).

\bibitem{McWeeny60} R. McWeeny,
Rev.\ Mod.\ Phys. {\bf 32}, 335 (1960).

\bibitem{Goedecker94} S. Goedecker and L. Colombo,
Phys.\ Rev.\ Lett. {\bf 73}, 122 (1994).

\bibitem{Palser98} A.\ H.\ R. Palser and D.\ E. Manolopoulos,
Phys.\ Rev.\ B {\bf 58}, 12704 (1998). 

\bibitem{Beylkin99} G. Beylkin, N. Coult, and M.\ J. Mohlenkamp,
J.\ Comp.\ Phys. {\bf 152}, 32 (1999).

\bibitem{Holas01} A. Holas, Chem.\ Phys.\ Lett.\ {\bf 340}, 552 (2001).

\bibitem{Niklasson02} A.\ M.\ N. Niklasson, C.\ J. Tymczak, and H. R\"oder,
{\it "A multi-resolution density matrix approach to electronic structure
calculations"} (unpublished).

\bibitem{Niklasson02b} A.\ M.\ N. Niklasson, {\it Expansion
algorithm for the density matrix}, (unpublished).

\bibitem{Kenney95} C.\ S. Kenney, and A.\ J. Laub,
IEEE Trans. Automat. Control {\bf 40}, 1330 (1995).

\bibitem{Kohn59} W. Kohn,
Phys.\ Rev.\ {\bf 115}, 809 (1959).

\bibitem{Baer97} R. Baer and M. Head-Gordon,
Phys.\ Rev.\ Lett. {\bf 79}, 3962 (1994).

\bibitem{Stephan00} U. Stephan, R.\ M. Martin, and D.\ A. Drabold,
Phys.\ Rev.\ B {\bf 62}, 6885 (2000)

\bibitem{Beylkin91} G. Beylkin, R. Coifman, and V. Rokhlin,
Commun.\ Pure Appl.\ Math. {\bf 44}, 141 (1991).

\bibitem{Goedecker99} S. Goedecker and O.\ V. Ivanov,
Phys.\ Rev.\ B {\bf 59}, 7270 (1999).

\bibitem{White92} S.\ R. White,
Phys.\ Rev.\ Lett. {\bf 69}, 19 2863 (1992).

\bibitem{Nemeth00} K.\ Nemeth, and G.\ E.\ Scuseria,
Journal of Chemical Physics. {\bf 113}, 6035 (2000).

\bibitem{Denman81} E.\ D. Denman, and J. Leyvaramos,
Applied Math. Comp. {\bf 8}, 237 (1981).

\bibitem{Howland83} J.\ L. Howland,
Linear algebra and its applications {\bf 49}, 221 (1983).~

\bibitem{Mondo} M. Challacombe and E. Schwengler,
J.\ Chem.\ Phys. {\bf 106}, 5526 (1997).
E. Schwengler, M. Challacombe and M. HeadGordon,
J.\ Chem.\ Phys. {\bf 106}, 9708 (1997).
M. Challacombe, J.\ Chem.\ Phys. {\bf 110}, 2332 (1999).
M.  Challacombe, J.\ Chem.\ Phys. {\bf 113}, 10037 (2000).


\end{references}

\begin{figure}
\caption{\small
\label{Conv}}
\end{figure}

\begin{figure}
\caption{\small 
Examples of spectral projection polynomials $P(x) = F(x) + \gamma G(x)$
for different values of the adjustment factor $\gamma \in [0,6]$.
\label{Fig_F_G}}
\end{figure}

\begin{figure}
\caption{\small
\label{ConvN}}
\end{figure}

\begin{figure}
\caption{\small
\label{Lin}}
\end{figure}

\end{document}
