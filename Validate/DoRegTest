#!/bin/bash --debug
###################################################################################
# DoRegTest some info 
#
# Regression testing MondoSCF ... 
#
# Interpretation of the results
#  test can be:
#    - 'OK' if the results match those of a previous run precisely. The execution time is also given.
#    - 'NEW' if they have not been executed previously. The reference result is generated 
#      automatically in this run. 
#    - 'RUNTIME FAILURE' if they stopped unexpectedly (e.g. core dump, or stop)
#    - 'WRONG' if they produce a result that deviates (even a tiny bit) from an old reference
#  the last two options generally mean that a bug has been introduced, which requires investigation.
#  since regtesting only yields information relative to a previously known result, it is most useful
#  to do a regtest before and after you make changes.
#
# Adding/resetting/creating tests to the testsuite
#  these is fully controlled by the following files in the MONDO/Validate directories
#  -TEST_DIRS  : is just a list of directories that contain tests. You can add your directory here.
#  -TEST_TYPES : this file allows you to create a new test type. I.e. to specify for which words should
# Command line switches to the do_regtest script (also configurable from within the script)
#  -nocvs    : do not access the CVS for any updating, makes regtesting fully local
#  -nopurge  : do not do a purge 
#  -nocompile: do not recompile
#  -noemail  : do not send an email
#  -cvsdate string : specify any string to cvs update (most likely used as "-D 2005-02-17")
#
########################################################################################################
#
# THESE VARIABLES WILL NEED CHANGING FOR YOUR LOCAL CONFIGURATION
#

#
# The following variables typically need no changes on Linux machine, but might need changes on
# other an OS
#

# *** how to execute an input file [ mondo_prefix input mondo_postfix ]
mondo_prefix="${MONDO_EXEC}/MondoSCF"
mondo_postfix=

# email address
#email="valeryw@lanl.gov"
email=""

# *** make and awk
make=make
#make=gmake
awk=awk
#awk=nawk

# *** a short and long version of the data, in a format that CVS understands
datum_full=`date --iso-8601="seconds"`
datum_short=`date --iso-8601="seconds"`
#datum_full=`date '+%Y-%m-%dT%H:%M:%S+0100'`
#datum_short=`date '+%Y-%m-%d'`

# *** default settings for command line switches
nocvs="cvs"
nopurge="purge"
nocompile="compile"
noemail="email"
cvsdate="-D $datum_full"

###################################################################################
#
# From here on no changes to the script should be needed
#
###################################################################################
#
# command line argument passing
#
###################################################################################
while [ $# -ge 1 ]; do
case $1 in
  # do not update the CVS
    -nocvs) nocvs="nocvs";;
  # do not do a realclean before building
    -nopurge) nopurge="nopurge";;
  # do not recompile
    -nocompile) nocompile="nocompile";;
  # do not send email's report
    -noemail) noemail="noemail";;
  # specify the full string "-D 2005-02-01" to get a check-out of a specific date
    -cvsdate) cvsdate=$2; shift;;
    *)  break;;
esac
shift
done
###################################################################################
#
# set up the initial directory structures
#
###################################################################################
function init_global(){
    dir_report=${MONDO_HOME}/Validate/REPORT
    mkdir -p ${dir_report}
    log_compile=${dir_report}/compile.log
    log_purge=${dir_report}/purge.log
    log_cvs=${dir_report}/cvs.log
    error_description_file=${dir_report}/error_summary
    error_file=${dir_report}/error_number
    report_file=${dir_report}/report_summary
    rm -fR ${error_description_file} ${error_file} ${log_compile} ${log_cvs} \
	${log_purge} ${report_file}
    touch  ${error_description_file} ${error_file} ${log_compile} ${log_cvs} \
	${log_purge} ${report_file}
}
###################################################################################
#
# simple function to beg and end the tests all in the same way
#
###################################################################################
function beg_test() {
echo "*************************** testing started ******************************"
echo " started on " `date`
echo " checking version ${cvsdate} "

echo "*************************** testing started ******************************" >> ${report_file}
echo " started on " `date`                                                        >> ${report_file}
echo " checking version ${cvsdate} "                                              >> ${report_file}
}

function end_test() {
echo "--------------------------------------------------------------------------"
date
echo "*************************** testing ended ********************************"

echo "--------------------------------------------------------------------------" >> ${report_file}
date                                                                              >> ${report_file}
echo "*************************** testing ended ********************************" >> ${report_file}
}

###################################################################################
#
# function to grep for changes in the output. Takes five arguments
#
###################################################################################
function do_test_grep(){
 output_new=$1
 output_old=$2
 error_file=$3
 grep_string=$4
 grep_field=$5
 #echo "grep_string ${grep_string}"
 #echo "grep_field ${grep_field}"
 e1=`grep -a "${grep_string}" ${output_old} | tail -1 | ${awk} -v f=${grep_field} '{print $f}'`
 e2=`grep -a "${grep_string}" ${output_new} | tail -1 | ${awk} -v f=${grep_field} '{print $f}'`
 big=`echo "${e1} ${e2}" | ${awk} '{v=sqrt((($1-$2)/$2)^2); if (v>1.0E-14) printf("%16.8e",v); else printf("0") ;}'`
 case ${big} in
 0)
  # ok, same energy
  return 0 ;;
 *)
  # nope too large
  echo "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" >> ${error_file}
  echo "${output_new} : " >> ${error_file}
  echo " ${grep_string} : old = ${e1} new = ${e2} " >> ${error_file}
  echo " relative error : ${big}  " >> ${error_file}
  echo "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" >> ${error_file}
  return 1 ;;
 esac
}
###################################################################################
#
# parse the TEST_TYPES file to do different kinds of test (done after cvs update)
#
# tests grep for the last line in the file where a string matches (test_grep)
# and compares a numeric field at a given column (test_col)
#
# the format of the TEST_TYPES file is (notice the '!' as a field separator, to allow
# for spaces in the test_grep)
#
# Ntest_types
# test_grep_1 ! test_col_1
# test_grep_2 ! test_col_2
# ....
# followed by comment lines
#
###################################################################################
function get_test_types(){
 test_types_file=$1
 Ntest_types=`awk -v l=1 -v c=1 'BEGIN{FS="!"}{lr=lr+1;if (lr==l) print $c}' ${test_types_file}`
 test_grep[0]=""
 test_col[0]=1
 t=1
 while [ $t -le ${Ntest_types} ]; do
     test_grep[t]=`${awk} -v l=$t -v c=1 'BEGIN{FS="!"}{lr=lr+1;if (lr==l+1) print $c}' ${test_types_file}`
     test_col[t]=`${awk} -v l=$t -v c=2 'BEGIN{FS="!"}{lr=lr+1;if (lr==l+1) print $c}' ${test_types_file}`
     #echo "test_grep $t = ${test_grep[t]}"
     #echo "test_col $t = ${test_col[t]}"
     let t=t+1
 done
}
###################################################################################
#
# send the report to the boss
#
###################################################################################
function sendemail(){
if [[ ${noemail} != "noemail" ]]; then
  mail -s "MondoSCF report summary ${datum_short}" ${email} < ${report_file}
fi
}
###################################################################################
#
# function to select which test to run
#
###################################################################################
function do_test() {
#
# *** start testing
#
beg_test
#
# *** cvs update
#
echo "------------------------- cvs update MondoSCF ----------------------------"
echo "------------------------- cvs update MondoSCF ----------------------------" >> ${report_file}
if [[ ${nocvs} != "nocvs" ]]; then
  #
  # *** cvs update src
  #
  cd ${MONDO_HOME}/
  cvs update -d -A ${cvsdate} &> ${log_cvs}
  if (( $? )); then
  echo "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" >> ${error_description_file}
  tail -20 ${log_cvs} >> ${error_description_file}
  echo "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" >> ${error_description_file}
  echo "error happened : no cvs update ... bailing out"
  echo "error happened : no cvs update ... bailing out" >> ${report_file}
  end_test 
  exit 1
  fi
  echo "requested : cvs update ... went fine"
  echo "requested : cvs update ... went fine" >> ${report_file}
else
  echo "requested : no cvs update"
  echo "requested : no cvs update" >> ${report_file}
fi
#
# *** make purge
#
echo "------------------------- purge MondoSCF ---------------------------------"
echo "------------------------- purge MondoSCF ---------------------------------" >> ${report_file}
if [[ ${nopurge} != "nopurge" ]]; then
   cd ${MONDO_HOME}
   ${make} purge &> ${log_purge}
   if (( $? )); then
      echo "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" >> \
	  ${error_description_file}
      tail -20 ${log_purge} >> ${error_description_file}
      echo "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" >> \
	  ${error_description_file}
      echo "error happened : make purge ... bailing out"
      echo "error happened : make purge ... bailing out" >> ${report_file}
      end_test
      exit 2
   else
      echo "requested : make purge ... went fine"
      echo "requested : make purge ... went fine" >> ${report_file}
   fi
else
  echo "requested : no purge"
  echo "requested : no purge" >> ${report_file}
fi
#
# *** from here failures are likely to be bugs in MondoSCF
#
echo "------------------------- compiling MondoSCF -----------------------------"
echo "------------------------- compiling MondoSCF -----------------------------" >> ${report_file}
if [[ ${nocompile} != "nocompile" ]]; then
    cd ${MONDO_HOME}
    ${make} all &> ${log_compile}
    if (( $? )); then
	echo "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" >> \
	    ${error_description_file}
	tail -20 ${log_compile} >> ${error_description_file}
	echo "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" >> \
	    ${error_description_file}
	echo "error happened : make all"
	echo "error happened : make all" >> ${report_file}
	cat "${error_description_file}"
	end_test 
	exit 3
    else
	compile_warnings=`grep "Warning:" ${log_compile} | wc | tail -1 |  ${awk} '{print $1}'`
	echo "requested : make all (${compile_warnings} warnings)"
	echo "requested : make all (${compile_warnings} warnings)" >> ${report_file}
    fi
else
    echo "requested : no compile"
    echo "requested : no compile" >> ${report_file}
fi
#
# *** now start testing
#
echo "------------------------- regtesting MondoSCF ----------------------------"
echo "------------------------- regtesting MondoSCF ----------------------------" >> ${report_file}
n_runtime_error=0
n_wrong_results=0
n_correct=0
n_tests=0
n_new=0
#
# execute all regtests
#
cd ${MONDO_HOME}/Validate
dirs=`cat ${MONDO_HOME}/Validate/TEST_DIRS | grep -v "#"`
MONDO_SCRATCH_TMP=${MONDO_SCRATCH}
for dir in ${dirs};
do
  cd ${MONDO_HOME}/Validate/${dir}
  rm -f *.out *.log *.xyz *.stdout *.pbs *.pbs.*
  #
  # read test type file
  #
  get_test_types TEST_TYPES
  #
  # create a subscratch dir
  #
  MONDO_SCRATCH=${MONDO_SCRATCH_TMP}/${dir}
  mkdir -p ${MONDO_SCRATCH}
  #
  # run the tests now
  #
  echo "Starting tests in ${MONDO_HOME}/Validate/${dir}"
  echo "Starting tests in ${MONDO_HOME}/Validate/${dir}" >> ${report_file}
  input_files=`ls *.inp | grep inp`
  for input_file in ${input_files}
    do
    file=${input_file%.inp}
    ref_file=${file}.ref
    output_file=${file}.out
    stdout_file=${file}.stdout
    log_file=${file}.log
    xyz_file=${file}.xyz
    n_tests=$((n_tests+1))
    this_test=""
#( ulimit -t 3000 ; ${mondo_prefix} ${input_file} ${output_file} ${log_file} ${xyz_file} ${mondo_postfix} &> ${stdout_file} ) &> /dev/null
    ( ulimit -S ; ${mondo_prefix} ${input_file} ${output_file} ${log_file} ${xyz_file} ${mondo_postfix} &> ${stdout_file} ) &> /dev/null
    #
    # *** MondoSCF failed obviously
    #
    echo "after ulimit $?"
    if (( $? )); then
	echo "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" >> \
	    ${error_description_file}
        echo ${output_file} >> ${error_description_file}
        tail -20 ${output_file} >> ${error_description_file}
	echo "---------------------------------------------------------------" >> \
	    ${error_description_file}
        tail -20 ${stdout_file} >> ${error_description_file}
        echo "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" >> \
	    ${error_description_file}
        this_test="RUNTIME FAIL 1"
        n_runtime_error=$((n_runtime_error+1))
    else
        #
        # *** but didn't end !?
	#
        grep -a "Successful MondoSCF run" ${output_file} &> /dev/null
        if (( $? )); then
	    echo "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" >> \
		${error_description_file}
	    echo ${output_file} >> ${error_description_file}
	    tail -20 ${output_file} >> ${error_description_file}
	    echo "---------------------------------------------------------------" >> \
		${error_description_file}
	    tail -20 ${stdout_file} >> ${error_description_file}
	    echo "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" >> \
		${error_description_file}
	    this_test="RUNTIME FAIL 2"
	    n_runtime_error=$((n_runtime_error+1))
        else
           # *** still running, you must be joking...
           # *** see if we manage to pass the testing
           # *** but only if we can compare
	   if [ -f ${ref_file} ]; then
	       m_correct=0
	       for ((itest=1;itest<=Ntest_types;itest++));
	       do
		 do_test_grep ${output_file} ${ref_file} ${error_file} "${test_grep[itest]}" "${test_col[itest]}"
                 if (( $? )); then
                    this_test="WRONG ${test_grep[itest]}"
                    n_wrong_results=$((n_wrong_results+1))
		    break;
                 else
                    this_test="OK"
		    m_correct=$((m_correct+1))
                 fi
               done
	       if ((m_correct==Ntest_types)); then
		   n_correct=$((n_correct+1))
	       fi
           else
	       this_test="NEW"
	       n_new=$((n_new+1))
           fi
        fi
     fi
     #
     # Keep the output up-to-date
     #
     case ${this_test} in
	 "NEW" )
	     cp ${output_file} ${ref_file}
	     timing=0
	     this_test="${this_test} (${timing} sec)" ;;
	 "OK" )
	     timing=0
	     this_test="${this_test} (${timing} sec)" ;;
     esac
     printf "%50s %20s\n" "${input_file}" "${this_test}"
     printf "%50s %20s\n" "${input_file}" "${this_test}" >> ${report_file}
  done
  #
  # clean subscratch dir
  #
  rm -rf ${MONDO_SCRATCH}
  MONDO_SCRATCH=${MONDO_SCRATCH_TMP}
done

echo "--------------------------------- summary --------------------------------"
printf "number of FAILED  tests %d\n" ${n_runtime_error}
printf "number of WRONG   tests %d\n" ${n_wrong_results}
printf "number of CORRECT tests %d\n" ${n_correct}
printf "number of NEW     tests %d\n" ${n_new}
printf "number of         tests %d\n" ${n_tests}

echo "--------------------------------- summary --------------------------------" >> ${report_file}
printf "number of FAILED  tests %d\n" ${n_runtime_error} >> ${report_file}
printf "number of WRONG   tests %d\n" ${n_wrong_results} >> ${report_file}
printf "number of CORRECT tests %d\n" ${n_correct}       >> ${report_file}
printf "number of NEW     tests %d\n" ${n_new}           >> ${report_file}
printf "number of         tests %d\n" ${n_tests}         >> ${report_file}

# *** end testing
end_test

}
###################################################################################
#
# start the jobs
#
###################################################################################


init_global

do_test

sendemail

exit 0



